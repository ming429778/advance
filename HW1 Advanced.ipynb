{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9f8a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a67993fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'HW1.train.csv'  # path to training data\n",
    "test_path = 'HW1.test.csv'   # path to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7c6e7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def plot_learning_curve(loss_record, title=''):\n",
    "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
    "    total_steps = len(loss_record['train'])\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
    "    figure(figsize=(6, 4))\n",
    "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
    "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    ''' Plot prediction of your DNN '''\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "\n",
    "    figure(figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0c03538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('HW1.train.csv')\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "data = clean_dataset(data)\n",
    "x = data[data.columns[1:94]]\n",
    "y = data[data.columns[94]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f35a677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Specs          Score\n",
      "75   tested_positive.1  112995.138726\n",
      "57     tested_positive   53249.271791\n",
      "42        hh_cmnty_cli    7783.153184\n",
      "60      hh_cmnty_cli.1    7713.712252\n",
      "78      hh_cmnty_cli.2    7572.365612\n",
      "43      nohh_cmnty_cli    6954.915166\n",
      "61    nohh_cmnty_cli.1    6863.334251\n",
      "79    nohh_cmnty_cli.2    6708.860666\n",
      "58               cli.1    5176.487362\n",
      "40                 cli    5133.480064\n",
      "76               cli.2    5125.427679\n",
      "41                 ili    4745.448707\n",
      "59               ili.1    4739.143963\n",
      "77               ili.2    4665.965887\n",
      "92  worried_finances.2     677.968387\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('HW1.train.csv')\n",
    "\n",
    "x = data[data.columns[1:94]]\n",
    "y = data[data.columns[94]]\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=f_regression, k=5)\n",
    "fit = bestfeatures.fit(x,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(x.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(15,'Score'))  #print 15 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "127739cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 mode='train',\n",
    "                 target_only=False):\n",
    "        self.mode = mode\n",
    "\n",
    "        # Read data into numpy arrays\n",
    "        with open(path, 'r') as fp:\n",
    "            data = list(csv.reader(fp))\n",
    "            data = np.array(data[1:])[:, 1:].astype(float)\n",
    "        \n",
    "        if not target_only:\n",
    "            feats = list(range(93))\n",
    "        else:\n",
    "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
    "            feats = [75, 57, 42, 60, 78, 43, 61, 79, 40, 58, 76, 41, 59, 77] #上面挑选的最优特征\n",
    "\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
    "            data = data[:, feats]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else:\n",
    "            # Training data (train/dev sets)\n",
    "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
    "            target = data[:, -1]\n",
    "            data = data[:, feats]\n",
    "\n",
    "            # Splitting training data into train & dev sets\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(data[indices])\n",
    "            self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features (you may remove this part to see what will happen)\n",
    "        self.data[:, 40:] = \\\n",
    "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
    "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5123b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a18d0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    ''' A simple fully-connected deep neural network '''\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        # Define your neural network here\n",
    "        # TODO: How to modify this model to achieve better performance?\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.BatchNorm1d(32),#使用BN，加速模型训练\n",
    "            nn.Dropout(p=0.2),#使用Dropout，减小过拟合，注意不能在BN之前\n",
    "            nn.LeakyReLU(),#更换激活函数\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        regularization_loss = 0\n",
    "        for param in model.parameters():\n",
    "        # TODO: you may implement L1/L2 regularization here\n",
    "        # L2 norm\n",
    "            # regularization_loss += torch.sum(abs(param))\n",
    "            regularization_loss += torch.sum(param ** 2)\n",
    "        return self.criterion(pred, target) + 0.00075 * regularization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "42034751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
    "                .format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0339c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "841528bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tt_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    preds = []\n",
    "    for x in tt_set:                            # iterate through the dataloader\n",
    "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            preds.append(pred.detach().cpu())   # collect prediction\n",
    "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bde81b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "target_only = True                   # TODO: Using 40 states & 2 tested_positive features\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 8000,                # maximum number of epochs\n",
    "    'batch_size': 200,               # mini-batch size for dataloader\n",
    "    'optimizer': 'Adam',              # 使用Adam优化器\n",
    "    'optim_hparas': {                # default learning rate\n",
    "        'lr': 0.0001,                 \n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55ad5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the train set of COVID19 Dataset (1800 samples found, each dim = 14)\n",
      "Finished reading the dev set of COVID19 Dataset (200 samples found, each dim = 14)\n",
      "Finished reading the test set of COVID19 Dataset (500 samples found, each dim = 14)\n"
     ]
    }
   ],
   "source": [
    "tr_set = prep_dataloader(train_path, 'train', config['batch_size'], target_only=target_only)\n",
    "dv_set = prep_dataloader(train_path, 'dev', config['batch_size'], target_only=target_only)\n",
    "tt_set = prep_dataloader(test_path, 'test', config['batch_size'], target_only=target_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a27228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6416f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model (epoch =    1, loss = 293.2087)\n",
      "Saving model (epoch =   13, loss = 293.0594)\n",
      "Saving model (epoch =   14, loss = 291.4718)\n",
      "Saving model (epoch =   15, loss = 290.1337)\n",
      "Saving model (epoch =   16, loss = 289.6721)\n",
      "Saving model (epoch =   17, loss = 289.5151)\n",
      "Saving model (epoch =   18, loss = 289.2418)\n",
      "Saving model (epoch =   19, loss = 289.0247)\n",
      "Saving model (epoch =   20, loss = 288.3987)\n",
      "Saving model (epoch =   21, loss = 288.1816)\n",
      "Saving model (epoch =   22, loss = 288.1190)\n",
      "Saving model (epoch =   23, loss = 287.5005)\n",
      "Saving model (epoch =   24, loss = 287.2608)\n",
      "Saving model (epoch =   25, loss = 287.1260)\n",
      "Saving model (epoch =   26, loss = 286.7260)\n",
      "Saving model (epoch =   27, loss = 285.8665)\n",
      "Saving model (epoch =   28, loss = 285.2419)\n",
      "Saving model (epoch =   29, loss = 284.2810)\n",
      "Saving model (epoch =   30, loss = 283.3094)\n",
      "Saving model (epoch =   31, loss = 281.9989)\n",
      "Saving model (epoch =   32, loss = 281.0447)\n",
      "Saving model (epoch =   33, loss = 280.6135)\n",
      "Saving model (epoch =   34, loss = 279.7369)\n",
      "Saving model (epoch =   35, loss = 279.1776)\n",
      "Saving model (epoch =   36, loss = 278.0732)\n",
      "Saving model (epoch =   37, loss = 277.7003)\n",
      "Saving model (epoch =   38, loss = 276.2304)\n",
      "Saving model (epoch =   39, loss = 274.7213)\n",
      "Saving model (epoch =   40, loss = 272.2588)\n",
      "Saving model (epoch =   41, loss = 268.5163)\n",
      "Saving model (epoch =   42, loss = 268.0490)\n",
      "Saving model (epoch =   49, loss = 267.9290)\n",
      "Saving model (epoch =   50, loss = 267.7338)\n",
      "Saving model (epoch =   51, loss = 267.1816)\n",
      "Saving model (epoch =   52, loss = 266.1953)\n",
      "Saving model (epoch =   54, loss = 265.9228)\n",
      "Saving model (epoch =   55, loss = 265.6932)\n",
      "Saving model (epoch =   56, loss = 264.9085)\n",
      "Saving model (epoch =   57, loss = 264.4127)\n",
      "Saving model (epoch =   58, loss = 263.3878)\n",
      "Saving model (epoch =   59, loss = 263.3465)\n",
      "Saving model (epoch =   60, loss = 262.7200)\n",
      "Saving model (epoch =   61, loss = 261.9649)\n",
      "Saving model (epoch =   62, loss = 261.8508)\n",
      "Saving model (epoch =   63, loss = 261.7603)\n",
      "Saving model (epoch =   64, loss = 260.9679)\n",
      "Saving model (epoch =   65, loss = 260.2548)\n",
      "Saving model (epoch =   66, loss = 259.1055)\n",
      "Saving model (epoch =   67, loss = 258.4969)\n",
      "Saving model (epoch =   69, loss = 257.9159)\n",
      "Saving model (epoch =   70, loss = 257.6820)\n",
      "Saving model (epoch =   71, loss = 257.0555)\n",
      "Saving model (epoch =   72, loss = 256.5218)\n",
      "Saving model (epoch =   73, loss = 256.1702)\n",
      "Saving model (epoch =   74, loss = 255.6300)\n",
      "Saving model (epoch =   75, loss = 255.0668)\n",
      "Saving model (epoch =   76, loss = 254.2982)\n",
      "Saving model (epoch =   77, loss = 253.0385)\n",
      "Saving model (epoch =   79, loss = 252.7454)\n",
      "Saving model (epoch =   80, loss = 251.6607)\n",
      "Saving model (epoch =   81, loss = 251.2532)\n",
      "Saving model (epoch =   82, loss = 250.5438)\n",
      "Saving model (epoch =   83, loss = 250.0033)\n",
      "Saving model (epoch =   84, loss = 249.1508)\n",
      "Saving model (epoch =   85, loss = 248.3329)\n",
      "Saving model (epoch =   86, loss = 247.8183)\n",
      "Saving model (epoch =   87, loss = 247.7432)\n",
      "Saving model (epoch =   88, loss = 246.9517)\n",
      "Saving model (epoch =   89, loss = 246.0350)\n",
      "Saving model (epoch =   90, loss = 245.7545)\n",
      "Saving model (epoch =   92, loss = 245.5235)\n",
      "Saving model (epoch =   93, loss = 244.7481)\n",
      "Saving model (epoch =   94, loss = 244.0983)\n",
      "Saving model (epoch =   95, loss = 243.6374)\n",
      "Saving model (epoch =   96, loss = 242.8791)\n",
      "Saving model (epoch =   97, loss = 242.6338)\n",
      "Saving model (epoch =   98, loss = 242.1805)\n",
      "Saving model (epoch =   99, loss = 240.3225)\n",
      "Saving model (epoch =  100, loss = 240.2973)\n",
      "Saving model (epoch =  101, loss = 239.3333)\n",
      "Saving model (epoch =  102, loss = 238.6174)\n",
      "Saving model (epoch =  103, loss = 237.3147)\n",
      "Saving model (epoch =  104, loss = 236.5909)\n",
      "Saving model (epoch =  105, loss = 235.9825)\n",
      "Saving model (epoch =  106, loss = 235.2140)\n",
      "Saving model (epoch =  107, loss = 234.6429)\n",
      "Saving model (epoch =  109, loss = 234.4338)\n",
      "Saving model (epoch =  110, loss = 233.3569)\n",
      "Saving model (epoch =  111, loss = 232.8333)\n",
      "Saving model (epoch =  112, loss = 232.6713)\n",
      "Saving model (epoch =  113, loss = 232.5185)\n",
      "Saving model (epoch =  114, loss = 231.8587)\n",
      "Saving model (epoch =  115, loss = 230.9421)\n",
      "Saving model (epoch =  116, loss = 230.8260)\n",
      "Saving model (epoch =  117, loss = 230.5338)\n",
      "Saving model (epoch =  118, loss = 230.2627)\n",
      "Saving model (epoch =  119, loss = 228.9342)\n",
      "Saving model (epoch =  120, loss = 228.2493)\n",
      "Saving model (epoch =  121, loss = 227.3733)\n",
      "Saving model (epoch =  122, loss = 227.1375)\n",
      "Saving model (epoch =  123, loss = 225.9947)\n",
      "Saving model (epoch =  124, loss = 225.1057)\n",
      "Saving model (epoch =  127, loss = 223.7893)\n",
      "Saving model (epoch =  128, loss = 222.9483)\n",
      "Saving model (epoch =  129, loss = 221.9879)\n",
      "Saving model (epoch =  131, loss = 221.0218)\n",
      "Saving model (epoch =  132, loss = 220.4846)\n",
      "Saving model (epoch =  133, loss = 219.2264)\n",
      "Saving model (epoch =  134, loss = 217.9716)\n",
      "Saving model (epoch =  135, loss = 217.9326)\n",
      "Saving model (epoch =  136, loss = 216.9313)\n",
      "Saving model (epoch =  137, loss = 216.5284)\n",
      "Saving model (epoch =  138, loss = 215.6397)\n",
      "Saving model (epoch =  139, loss = 214.4115)\n",
      "Saving model (epoch =  140, loss = 214.1765)\n",
      "Saving model (epoch =  141, loss = 214.0445)\n",
      "Saving model (epoch =  142, loss = 213.5594)\n",
      "Saving model (epoch =  143, loss = 212.2844)\n",
      "Saving model (epoch =  144, loss = 212.0298)\n",
      "Saving model (epoch =  145, loss = 211.6768)\n",
      "Saving model (epoch =  146, loss = 211.3177)\n",
      "Saving model (epoch =  147, loss = 210.0243)\n",
      "Saving model (epoch =  149, loss = 208.5943)\n",
      "Saving model (epoch =  151, loss = 208.4765)\n",
      "Saving model (epoch =  152, loss = 207.4880)\n",
      "Saving model (epoch =  153, loss = 207.4348)\n",
      "Saving model (epoch =  154, loss = 206.1852)\n",
      "Saving model (epoch =  155, loss = 205.2772)\n",
      "Saving model (epoch =  156, loss = 204.9877)\n",
      "Saving model (epoch =  157, loss = 204.6517)\n",
      "Saving model (epoch =  158, loss = 204.2984)\n",
      "Saving model (epoch =  159, loss = 203.4988)\n",
      "Saving model (epoch =  160, loss = 202.2101)\n",
      "Saving model (epoch =  162, loss = 200.4857)\n",
      "Saving model (epoch =  163, loss = 199.6724)\n",
      "Saving model (epoch =  164, loss = 199.1955)\n",
      "Saving model (epoch =  166, loss = 198.1416)\n",
      "Saving model (epoch =  167, loss = 197.1245)\n",
      "Saving model (epoch =  169, loss = 196.2467)\n",
      "Saving model (epoch =  170, loss = 195.1875)\n",
      "Saving model (epoch =  172, loss = 195.1037)\n",
      "Saving model (epoch =  173, loss = 194.5137)\n",
      "Saving model (epoch =  174, loss = 194.0892)\n",
      "Saving model (epoch =  175, loss = 192.7760)\n",
      "Saving model (epoch =  176, loss = 192.7317)\n",
      "Saving model (epoch =  177, loss = 191.6477)\n",
      "Saving model (epoch =  178, loss = 191.6092)\n",
      "Saving model (epoch =  179, loss = 190.9397)\n",
      "Saving model (epoch =  181, loss = 189.8834)\n",
      "Saving model (epoch =  182, loss = 188.5386)\n",
      "Saving model (epoch =  183, loss = 187.0779)\n",
      "Saving model (epoch =  184, loss = 185.2189)\n",
      "Saving model (epoch =  185, loss = 183.2478)\n",
      "Saving model (epoch =  186, loss = 183.2315)\n",
      "Saving model (epoch =  188, loss = 183.0245)\n",
      "Saving model (epoch =  190, loss = 182.8520)\n",
      "Saving model (epoch =  191, loss = 181.8474)\n",
      "Saving model (epoch =  192, loss = 180.7995)\n",
      "Saving model (epoch =  193, loss = 180.3597)\n",
      "Saving model (epoch =  195, loss = 179.8743)\n",
      "Saving model (epoch =  196, loss = 179.3931)\n",
      "Saving model (epoch =  197, loss = 177.7013)\n",
      "Saving model (epoch =  198, loss = 177.5652)\n",
      "Saving model (epoch =  199, loss = 176.2949)\n",
      "Saving model (epoch =  200, loss = 175.0022)\n",
      "Saving model (epoch =  201, loss = 173.3681)\n",
      "Saving model (epoch =  202, loss = 172.4030)\n",
      "Saving model (epoch =  203, loss = 171.5937)\n",
      "Saving model (epoch =  204, loss = 169.7631)\n",
      "Saving model (epoch =  205, loss = 169.6850)\n",
      "Saving model (epoch =  207, loss = 168.4855)\n",
      "Saving model (epoch =  208, loss = 167.1738)\n",
      "Saving model (epoch =  214, loss = 166.7940)\n",
      "Saving model (epoch =  215, loss = 164.7834)\n",
      "Saving model (epoch =  216, loss = 164.5781)\n",
      "Saving model (epoch =  217, loss = 163.4070)\n",
      "Saving model (epoch =  218, loss = 163.0467)\n",
      "Saving model (epoch =  219, loss = 162.8992)\n",
      "Saving model (epoch =  220, loss = 161.7870)\n",
      "Saving model (epoch =  221, loss = 161.6064)\n",
      "Saving model (epoch =  222, loss = 160.7767)\n",
      "Saving model (epoch =  223, loss = 159.6441)\n",
      "Saving model (epoch =  225, loss = 158.4737)\n",
      "Saving model (epoch =  227, loss = 157.5218)\n",
      "Saving model (epoch =  228, loss = 156.9104)\n",
      "Saving model (epoch =  229, loss = 156.7281)\n",
      "Saving model (epoch =  230, loss = 155.3376)\n",
      "Saving model (epoch =  233, loss = 153.0813)\n",
      "Saving model (epoch =  236, loss = 152.2682)\n",
      "Saving model (epoch =  239, loss = 149.9146)\n",
      "Saving model (epoch =  240, loss = 149.2710)\n",
      "Saving model (epoch =  241, loss = 148.6875)\n",
      "Saving model (epoch =  242, loss = 146.3619)\n",
      "Saving model (epoch =  243, loss = 144.5097)\n",
      "Saving model (epoch =  244, loss = 144.4217)\n",
      "Saving model (epoch =  245, loss = 144.3969)\n",
      "Saving model (epoch =  246, loss = 142.8104)\n",
      "Saving model (epoch =  250, loss = 142.6408)\n",
      "Saving model (epoch =  252, loss = 142.3308)\n",
      "Saving model (epoch =  253, loss = 141.3039)\n",
      "Saving model (epoch =  254, loss = 139.3229)\n",
      "Saving model (epoch =  255, loss = 139.1587)\n",
      "Saving model (epoch =  256, loss = 138.9520)\n",
      "Saving model (epoch =  257, loss = 138.8520)\n",
      "Saving model (epoch =  258, loss = 137.2967)\n",
      "Saving model (epoch =  259, loss = 135.4727)\n",
      "Saving model (epoch =  260, loss = 133.5054)\n",
      "Saving model (epoch =  266, loss = 132.1548)\n",
      "Saving model (epoch =  267, loss = 131.0659)\n",
      "Saving model (epoch =  268, loss = 130.7395)\n",
      "Saving model (epoch =  271, loss = 130.0414)\n",
      "Saving model (epoch =  272, loss = 128.5388)\n",
      "Saving model (epoch =  274, loss = 127.3493)\n",
      "Saving model (epoch =  275, loss = 125.8823)\n",
      "Saving model (epoch =  276, loss = 125.6055)\n",
      "Saving model (epoch =  278, loss = 125.0687)\n",
      "Saving model (epoch =  280, loss = 124.0551)\n",
      "Saving model (epoch =  281, loss = 123.4849)\n",
      "Saving model (epoch =  282, loss = 123.0374)\n",
      "Saving model (epoch =  283, loss = 122.4231)\n",
      "Saving model (epoch =  284, loss = 121.3865)\n",
      "Saving model (epoch =  285, loss = 120.7026)\n",
      "Saving model (epoch =  286, loss = 119.4944)\n",
      "Saving model (epoch =  288, loss = 119.2851)\n",
      "Saving model (epoch =  289, loss = 118.2465)\n",
      "Saving model (epoch =  290, loss = 117.5257)\n",
      "Saving model (epoch =  291, loss = 116.9543)\n",
      "Saving model (epoch =  294, loss = 116.9039)\n",
      "Saving model (epoch =  296, loss = 115.1103)\n",
      "Saving model (epoch =  297, loss = 114.2865)\n",
      "Saving model (epoch =  298, loss = 113.5781)\n",
      "Saving model (epoch =  299, loss = 112.3654)\n",
      "Saving model (epoch =  300, loss = 111.8972)\n",
      "Saving model (epoch =  302, loss = 111.6160)\n",
      "Saving model (epoch =  303, loss = 111.1829)\n",
      "Saving model (epoch =  304, loss = 109.9467)\n",
      "Saving model (epoch =  305, loss = 108.9574)\n",
      "Saving model (epoch =  307, loss = 108.6653)\n",
      "Saving model (epoch =  309, loss = 107.5796)\n",
      "Saving model (epoch =  310, loss = 106.6577)\n",
      "Saving model (epoch =  311, loss = 105.9849)\n",
      "Saving model (epoch =  312, loss = 105.8240)\n",
      "Saving model (epoch =  314, loss = 105.4529)\n",
      "Saving model (epoch =  315, loss = 104.2817)\n",
      "Saving model (epoch =  316, loss = 103.1546)\n",
      "Saving model (epoch =  317, loss = 102.5729)\n",
      "Saving model (epoch =  318, loss = 102.4786)\n",
      "Saving model (epoch =  319, loss = 101.6728)\n",
      "Saving model (epoch =  320, loss = 100.8092)\n",
      "Saving model (epoch =  325, loss = 98.1610)\n",
      "Saving model (epoch =  326, loss = 97.8741)\n",
      "Saving model (epoch =  327, loss = 97.4392)\n",
      "Saving model (epoch =  328, loss = 96.2406)\n",
      "Saving model (epoch =  330, loss = 95.9223)\n",
      "Saving model (epoch =  332, loss = 95.6265)\n",
      "Saving model (epoch =  333, loss = 94.7188)\n",
      "Saving model (epoch =  334, loss = 93.3813)\n",
      "Saving model (epoch =  335, loss = 93.3522)\n",
      "Saving model (epoch =  336, loss = 89.9504)\n",
      "Saving model (epoch =  337, loss = 86.9946)\n",
      "Saving model (epoch =  338, loss = 84.7874)\n",
      "Saving model (epoch =  339, loss = 81.7026)\n",
      "Saving model (epoch =  340, loss = 79.5386)\n",
      "Saving model (epoch =  363, loss = 78.9293)\n",
      "Saving model (epoch =  364, loss = 77.8507)\n",
      "Saving model (epoch =  371, loss = 74.9194)\n",
      "Saving model (epoch =  379, loss = 73.9405)\n",
      "Saving model (epoch =  380, loss = 70.0416)\n",
      "Saving model (epoch =  390, loss = 68.0987)\n",
      "Saving model (epoch =  391, loss = 66.0442)\n",
      "Saving model (epoch =  400, loss = 61.3084)\n",
      "Saving model (epoch =  410, loss = 60.5835)\n",
      "Saving model (epoch =  415, loss = 56.7878)\n",
      "Saving model (epoch =  423, loss = 54.9307)\n",
      "Saving model (epoch =  429, loss = 53.3196)\n",
      "Saving model (epoch =  430, loss = 52.5272)\n",
      "Saving model (epoch =  440, loss = 50.2860)\n",
      "Saving model (epoch =  445, loss = 46.6474)\n",
      "Saving model (epoch =  454, loss = 45.6491)\n",
      "Saving model (epoch =  456, loss = 44.0925)\n",
      "Saving model (epoch =  464, loss = 43.6602)\n",
      "Saving model (epoch =  467, loss = 42.9252)\n",
      "Saving model (epoch =  468, loss = 42.3754)\n",
      "Saving model (epoch =  474, loss = 41.9969)\n",
      "Saving model (epoch =  475, loss = 40.4234)\n",
      "Saving model (epoch =  479, loss = 38.3861)\n",
      "Saving model (epoch =  485, loss = 36.5686)\n",
      "Saving model (epoch =  494, loss = 34.1169)\n",
      "Saving model (epoch =  495, loss = 30.2500)\n",
      "Saving model (epoch =  496, loss = 29.0284)\n",
      "Saving model (epoch =  522, loss = 28.2578)\n",
      "Saving model (epoch =  525, loss = 28.1841)\n",
      "Saving model (epoch =  527, loss = 26.3613)\n",
      "Saving model (epoch =  531, loss = 26.0032)\n",
      "Saving model (epoch =  534, loss = 24.0845)\n",
      "Saving model (epoch =  549, loss = 23.7304)\n",
      "Saving model (epoch =  551, loss = 23.6248)\n",
      "Saving model (epoch =  553, loss = 23.5746)\n",
      "Saving model (epoch =  554, loss = 22.5863)\n",
      "Saving model (epoch =  555, loss = 22.4152)\n",
      "Saving model (epoch =  557, loss = 21.2595)\n",
      "Saving model (epoch =  563, loss = 20.9296)\n",
      "Saving model (epoch =  569, loss = 18.4074)\n",
      "Saving model (epoch =  580, loss = 17.7876)\n",
      "Saving model (epoch =  591, loss = 15.9668)\n",
      "Saving model (epoch =  595, loss = 15.5757)\n",
      "Saving model (epoch =  610, loss = 13.7744)\n",
      "Saving model (epoch =  619, loss = 13.5183)\n",
      "Saving model (epoch =  629, loss = 12.8729)\n",
      "Saving model (epoch =  645, loss = 11.2745)\n",
      "Saving model (epoch =  671, loss = 11.0367)\n",
      "Saving model (epoch =  686, loss = 10.9810)\n",
      "Saving model (epoch =  689, loss = 10.6130)\n",
      "Saving model (epoch =  707, loss = 10.2973)\n",
      "Saving model (epoch =  714, loss = 10.2023)\n",
      "Saving model (epoch =  722, loss = 9.8188)\n",
      "Saving model (epoch =  731, loss = 9.7173)\n",
      "Saving model (epoch =  742, loss = 9.4432)\n",
      "Saving model (epoch =  766, loss = 9.3744)\n",
      "Saving model (epoch =  777, loss = 9.1069)\n",
      "Saving model (epoch =  793, loss = 9.0201)\n",
      "Saving model (epoch =  796, loss = 9.0192)\n",
      "Saving model (epoch =  803, loss = 8.9531)\n",
      "Saving model (epoch =  807, loss = 8.9430)\n",
      "Saving model (epoch =  820, loss = 8.7904)\n",
      "Saving model (epoch =  833, loss = 8.7732)\n",
      "Saving model (epoch =  849, loss = 8.7586)\n",
      "Saving model (epoch =  854, loss = 8.6889)\n",
      "Saving model (epoch =  860, loss = 8.6558)\n",
      "Saving model (epoch =  871, loss = 8.5120)\n",
      "Saving model (epoch =  889, loss = 8.4290)\n",
      "Saving model (epoch =  897, loss = 8.3903)\n",
      "Saving model (epoch =  899, loss = 8.3863)\n",
      "Saving model (epoch =  902, loss = 8.3647)\n",
      "Saving model (epoch =  907, loss = 8.2496)\n",
      "Saving model (epoch =  915, loss = 8.0984)\n",
      "Saving model (epoch =  919, loss = 8.0665)\n",
      "Saving model (epoch =  929, loss = 8.0072)\n",
      "Saving model (epoch =  945, loss = 7.9979)\n",
      "Saving model (epoch =  946, loss = 7.8796)\n",
      "Saving model (epoch =  960, loss = 7.8028)\n",
      "Saving model (epoch =  963, loss = 7.7059)\n",
      "Saving model (epoch =  967, loss = 7.6801)\n",
      "Saving model (epoch =  970, loss = 7.6791)\n",
      "Saving model (epoch =  971, loss = 7.6087)\n",
      "Saving model (epoch =  980, loss = 7.5495)\n",
      "Saving model (epoch =  981, loss = 7.5292)\n",
      "Saving model (epoch =  990, loss = 7.5119)\n",
      "Saving model (epoch =  991, loss = 7.5099)\n",
      "Saving model (epoch =  995, loss = 7.4224)\n",
      "Saving model (epoch =  997, loss = 7.3482)\n",
      "Saving model (epoch = 1000, loss = 7.3319)\n",
      "Saving model (epoch = 1005, loss = 7.2962)\n",
      "Saving model (epoch = 1012, loss = 7.2697)\n",
      "Saving model (epoch = 1013, loss = 7.2626)\n",
      "Saving model (epoch = 1021, loss = 7.1297)\n",
      "Saving model (epoch = 1024, loss = 7.1154)\n",
      "Saving model (epoch = 1027, loss = 7.0973)\n",
      "Saving model (epoch = 1029, loss = 7.0250)\n",
      "Saving model (epoch = 1030, loss = 6.9661)\n",
      "Saving model (epoch = 1044, loss = 6.9553)\n",
      "Saving model (epoch = 1047, loss = 6.8980)\n",
      "Saving model (epoch = 1052, loss = 6.8367)\n",
      "Saving model (epoch = 1060, loss = 6.8122)\n",
      "Saving model (epoch = 1072, loss = 6.7600)\n",
      "Saving model (epoch = 1073, loss = 6.6381)\n",
      "Saving model (epoch = 1075, loss = 6.6199)\n",
      "Saving model (epoch = 1083, loss = 6.5669)\n",
      "Saving model (epoch = 1084, loss = 6.5026)\n",
      "Saving model (epoch = 1096, loss = 6.4355)\n",
      "Saving model (epoch = 1097, loss = 6.4277)\n",
      "Saving model (epoch = 1098, loss = 6.3866)\n",
      "Saving model (epoch = 1103, loss = 6.3378)\n",
      "Saving model (epoch = 1105, loss = 6.3258)\n",
      "Saving model (epoch = 1108, loss = 6.2395)\n",
      "Saving model (epoch = 1123, loss = 6.1237)\n",
      "Saving model (epoch = 1129, loss = 6.0238)\n",
      "Saving model (epoch = 1136, loss = 6.0005)\n",
      "Saving model (epoch = 1140, loss = 5.9476)\n",
      "Saving model (epoch = 1142, loss = 5.8933)\n",
      "Saving model (epoch = 1146, loss = 5.8643)\n",
      "Saving model (epoch = 1155, loss = 5.7266)\n",
      "Saving model (epoch = 1169, loss = 5.7264)\n",
      "Saving model (epoch = 1172, loss = 5.7021)\n",
      "Saving model (epoch = 1176, loss = 5.6432)\n",
      "Saving model (epoch = 1177, loss = 5.6252)\n",
      "Saving model (epoch = 1181, loss = 5.5205)\n",
      "Saving model (epoch = 1197, loss = 5.5002)\n",
      "Saving model (epoch = 1198, loss = 5.4536)\n",
      "Saving model (epoch = 1200, loss = 5.3989)\n",
      "Saving model (epoch = 1203, loss = 5.3242)\n",
      "Saving model (epoch = 1213, loss = 5.3114)\n",
      "Saving model (epoch = 1220, loss = 5.2445)\n",
      "Saving model (epoch = 1228, loss = 5.1765)\n",
      "Saving model (epoch = 1229, loss = 5.1751)\n",
      "Saving model (epoch = 1238, loss = 5.0864)\n",
      "Saving model (epoch = 1241, loss = 5.0512)\n",
      "Saving model (epoch = 1249, loss = 4.9984)\n",
      "Saving model (epoch = 1251, loss = 4.9965)\n",
      "Saving model (epoch = 1256, loss = 4.9388)\n",
      "Saving model (epoch = 1259, loss = 4.9048)\n",
      "Saving model (epoch = 1260, loss = 4.8980)\n",
      "Saving model (epoch = 1261, loss = 4.8637)\n",
      "Saving model (epoch = 1269, loss = 4.7953)\n",
      "Saving model (epoch = 1273, loss = 4.7379)\n",
      "Saving model (epoch = 1283, loss = 4.7061)\n",
      "Saving model (epoch = 1287, loss = 4.6811)\n",
      "Saving model (epoch = 1293, loss = 4.6053)\n",
      "Saving model (epoch = 1297, loss = 4.5167)\n",
      "Saving model (epoch = 1299, loss = 4.4218)\n",
      "Saving model (epoch = 1316, loss = 4.4141)\n",
      "Saving model (epoch = 1320, loss = 4.3509)\n",
      "Saving model (epoch = 1322, loss = 4.3404)\n",
      "Saving model (epoch = 1329, loss = 4.3346)\n",
      "Saving model (epoch = 1335, loss = 4.2790)\n",
      "Saving model (epoch = 1336, loss = 4.2732)\n",
      "Saving model (epoch = 1339, loss = 4.2511)\n",
      "Saving model (epoch = 1342, loss = 4.1957)\n",
      "Saving model (epoch = 1345, loss = 4.1575)\n",
      "Saving model (epoch = 1350, loss = 4.1530)\n",
      "Saving model (epoch = 1352, loss = 4.1395)\n",
      "Saving model (epoch = 1357, loss = 4.1156)\n",
      "Saving model (epoch = 1358, loss = 4.1060)\n",
      "Saving model (epoch = 1364, loss = 4.0740)\n",
      "Saving model (epoch = 1368, loss = 3.9804)\n",
      "Saving model (epoch = 1371, loss = 3.9727)\n",
      "Saving model (epoch = 1376, loss = 3.9472)\n",
      "Saving model (epoch = 1377, loss = 3.9290)\n",
      "Saving model (epoch = 1381, loss = 3.9191)\n",
      "Saving model (epoch = 1388, loss = 3.8877)\n",
      "Saving model (epoch = 1391, loss = 3.8683)\n",
      "Saving model (epoch = 1393, loss = 3.8628)\n",
      "Saving model (epoch = 1394, loss = 3.8458)\n",
      "Saving model (epoch = 1397, loss = 3.8403)\n",
      "Saving model (epoch = 1403, loss = 3.8244)\n",
      "Saving model (epoch = 1404, loss = 3.7920)\n",
      "Saving model (epoch = 1409, loss = 3.7604)\n",
      "Saving model (epoch = 1412, loss = 3.7542)\n",
      "Saving model (epoch = 1414, loss = 3.6456)\n",
      "Saving model (epoch = 1425, loss = 3.6288)\n",
      "Saving model (epoch = 1430, loss = 3.6013)\n",
      "Saving model (epoch = 1433, loss = 3.5947)\n",
      "Saving model (epoch = 1435, loss = 3.5074)\n",
      "Saving model (epoch = 1441, loss = 3.5051)\n",
      "Saving model (epoch = 1445, loss = 3.4702)\n",
      "Saving model (epoch = 1446, loss = 3.4611)\n",
      "Saving model (epoch = 1453, loss = 3.4603)\n",
      "Saving model (epoch = 1454, loss = 3.4246)\n",
      "Saving model (epoch = 1462, loss = 3.3727)\n",
      "Saving model (epoch = 1470, loss = 3.3675)\n",
      "Saving model (epoch = 1473, loss = 3.2965)\n",
      "Saving model (epoch = 1474, loss = 3.2905)\n",
      "Saving model (epoch = 1483, loss = 3.2745)\n",
      "Saving model (epoch = 1484, loss = 3.2631)\n",
      "Saving model (epoch = 1487, loss = 3.2418)\n",
      "Saving model (epoch = 1489, loss = 3.2049)\n",
      "Saving model (epoch = 1490, loss = 3.1915)\n",
      "Saving model (epoch = 1494, loss = 3.1807)\n",
      "Saving model (epoch = 1499, loss = 3.1300)\n",
      "Saving model (epoch = 1501, loss = 3.1175)\n",
      "Saving model (epoch = 1503, loss = 3.0748)\n",
      "Saving model (epoch = 1508, loss = 3.0729)\n",
      "Saving model (epoch = 1523, loss = 3.0506)\n",
      "Saving model (epoch = 1527, loss = 3.0459)\n",
      "Saving model (epoch = 1528, loss = 3.0169)\n",
      "Saving model (epoch = 1530, loss = 3.0156)\n",
      "Saving model (epoch = 1531, loss = 2.9926)\n",
      "Saving model (epoch = 1536, loss = 2.9674)\n",
      "Saving model (epoch = 1542, loss = 2.9575)\n",
      "Saving model (epoch = 1544, loss = 2.9556)\n",
      "Saving model (epoch = 1548, loss = 2.9340)\n",
      "Saving model (epoch = 1550, loss = 2.9010)\n",
      "Saving model (epoch = 1554, loss = 2.8648)\n",
      "Saving model (epoch = 1555, loss = 2.8615)\n",
      "Saving model (epoch = 1567, loss = 2.7885)\n",
      "Saving model (epoch = 1574, loss = 2.7823)\n",
      "Saving model (epoch = 1582, loss = 2.7571)\n",
      "Saving model (epoch = 1585, loss = 2.7498)\n",
      "Saving model (epoch = 1589, loss = 2.7366)\n",
      "Saving model (epoch = 1593, loss = 2.6963)\n",
      "Saving model (epoch = 1594, loss = 2.6852)\n",
      "Saving model (epoch = 1609, loss = 2.6627)\n",
      "Saving model (epoch = 1613, loss = 2.5883)\n",
      "Saving model (epoch = 1627, loss = 2.5857)\n",
      "Saving model (epoch = 1629, loss = 2.5620)\n",
      "Saving model (epoch = 1636, loss = 2.4912)\n",
      "Saving model (epoch = 1647, loss = 2.4736)\n",
      "Saving model (epoch = 1649, loss = 2.4544)\n",
      "Saving model (epoch = 1658, loss = 2.4203)\n",
      "Saving model (epoch = 1670, loss = 2.3916)\n",
      "Saving model (epoch = 1674, loss = 2.3485)\n",
      "Saving model (epoch = 1685, loss = 2.3355)\n",
      "Saving model (epoch = 1694, loss = 2.3314)\n",
      "Saving model (epoch = 1695, loss = 2.3095)\n",
      "Saving model (epoch = 1697, loss = 2.2790)\n",
      "Saving model (epoch = 1703, loss = 2.2631)\n",
      "Saving model (epoch = 1704, loss = 2.2507)\n",
      "Saving model (epoch = 1710, loss = 2.2473)\n",
      "Saving model (epoch = 1712, loss = 2.2381)\n",
      "Saving model (epoch = 1714, loss = 2.2132)\n",
      "Saving model (epoch = 1716, loss = 2.2047)\n",
      "Saving model (epoch = 1730, loss = 2.1756)\n",
      "Saving model (epoch = 1739, loss = 2.1448)\n",
      "Saving model (epoch = 1747, loss = 2.1123)\n",
      "Saving model (epoch = 1748, loss = 2.1050)\n",
      "Saving model (epoch = 1750, loss = 2.1007)\n",
      "Saving model (epoch = 1764, loss = 2.0529)\n",
      "Saving model (epoch = 1765, loss = 2.0403)\n",
      "Saving model (epoch = 1779, loss = 2.0372)\n",
      "Saving model (epoch = 1783, loss = 2.0184)\n",
      "Saving model (epoch = 1784, loss = 1.9928)\n",
      "Saving model (epoch = 1785, loss = 1.9750)\n",
      "Saving model (epoch = 1797, loss = 1.9749)\n",
      "Saving model (epoch = 1799, loss = 1.9663)\n",
      "Saving model (epoch = 1806, loss = 1.9438)\n",
      "Saving model (epoch = 1807, loss = 1.9318)\n",
      "Saving model (epoch = 1813, loss = 1.9256)\n",
      "Saving model (epoch = 1817, loss = 1.9186)\n",
      "Saving model (epoch = 1818, loss = 1.9176)\n",
      "Saving model (epoch = 1820, loss = 1.8866)\n",
      "Saving model (epoch = 1827, loss = 1.8741)\n",
      "Saving model (epoch = 1832, loss = 1.8504)\n",
      "Saving model (epoch = 1847, loss = 1.8273)\n",
      "Saving model (epoch = 1857, loss = 1.7804)\n",
      "Saving model (epoch = 1870, loss = 1.7724)\n",
      "Saving model (epoch = 1875, loss = 1.7378)\n",
      "Saving model (epoch = 1886, loss = 1.7008)\n",
      "Saving model (epoch = 1900, loss = 1.6864)\n",
      "Saving model (epoch = 1905, loss = 1.6731)\n",
      "Saving model (epoch = 1908, loss = 1.6706)\n",
      "Saving model (epoch = 1913, loss = 1.6642)\n",
      "Saving model (epoch = 1914, loss = 1.6417)\n",
      "Saving model (epoch = 1937, loss = 1.6107)\n",
      "Saving model (epoch = 1946, loss = 1.5765)\n",
      "Saving model (epoch = 1951, loss = 1.5653)\n",
      "Saving model (epoch = 1962, loss = 1.5588)\n",
      "Saving model (epoch = 1978, loss = 1.5514)\n",
      "Saving model (epoch = 1982, loss = 1.5320)\n",
      "Saving model (epoch = 1984, loss = 1.5026)\n",
      "Saving model (epoch = 1985, loss = 1.4970)\n",
      "Saving model (epoch = 2005, loss = 1.4729)\n",
      "Saving model (epoch = 2009, loss = 1.4436)\n",
      "Saving model (epoch = 2033, loss = 1.4395)\n",
      "Saving model (epoch = 2037, loss = 1.4241)\n",
      "Saving model (epoch = 2038, loss = 1.4206)\n",
      "Saving model (epoch = 2056, loss = 1.4165)\n",
      "Saving model (epoch = 2059, loss = 1.3978)\n",
      "Saving model (epoch = 2079, loss = 1.3970)\n",
      "Saving model (epoch = 2081, loss = 1.3936)\n",
      "Saving model (epoch = 2082, loss = 1.3748)\n",
      "Saving model (epoch = 2104, loss = 1.3506)\n",
      "Saving model (epoch = 2119, loss = 1.3505)\n",
      "Saving model (epoch = 2120, loss = 1.3472)\n",
      "Saving model (epoch = 2128, loss = 1.3470)\n",
      "Saving model (epoch = 2135, loss = 1.3298)\n",
      "Saving model (epoch = 2136, loss = 1.3281)\n",
      "Saving model (epoch = 2138, loss = 1.3097)\n",
      "Saving model (epoch = 2146, loss = 1.3072)\n",
      "Saving model (epoch = 2158, loss = 1.2982)\n",
      "Saving model (epoch = 2159, loss = 1.2906)\n",
      "Saving model (epoch = 2160, loss = 1.2839)\n",
      "Saving model (epoch = 2180, loss = 1.2822)\n",
      "Saving model (epoch = 2182, loss = 1.2691)\n",
      "Saving model (epoch = 2184, loss = 1.2615)\n",
      "Saving model (epoch = 2188, loss = 1.2395)\n",
      "Saving model (epoch = 2189, loss = 1.2373)\n",
      "Saving model (epoch = 2200, loss = 1.2291)\n",
      "Saving model (epoch = 2213, loss = 1.2145)\n",
      "Saving model (epoch = 2220, loss = 1.2103)\n",
      "Saving model (epoch = 2229, loss = 1.2001)\n",
      "Saving model (epoch = 2235, loss = 1.1968)\n",
      "Saving model (epoch = 2246, loss = 1.1916)\n",
      "Saving model (epoch = 2253, loss = 1.1882)\n",
      "Saving model (epoch = 2256, loss = 1.1839)\n",
      "Saving model (epoch = 2262, loss = 1.1693)\n",
      "Saving model (epoch = 2265, loss = 1.1657)\n",
      "Saving model (epoch = 2290, loss = 1.1568)\n",
      "Saving model (epoch = 2292, loss = 1.1561)\n",
      "Saving model (epoch = 2294, loss = 1.1483)\n",
      "Saving model (epoch = 2296, loss = 1.1381)\n",
      "Saving model (epoch = 2303, loss = 1.1311)\n",
      "Saving model (epoch = 2328, loss = 1.1309)\n",
      "Saving model (epoch = 2340, loss = 1.1254)\n",
      "Saving model (epoch = 2350, loss = 1.1170)\n",
      "Saving model (epoch = 2363, loss = 1.1101)\n",
      "Saving model (epoch = 2379, loss = 1.1071)\n",
      "Saving model (epoch = 2384, loss = 1.0991)\n",
      "Saving model (epoch = 2386, loss = 1.0922)\n",
      "Saving model (epoch = 2387, loss = 1.0881)\n",
      "Saving model (epoch = 2392, loss = 1.0803)\n",
      "Saving model (epoch = 2394, loss = 1.0749)\n",
      "Saving model (epoch = 2415, loss = 1.0746)\n",
      "Saving model (epoch = 2425, loss = 1.0672)\n",
      "Saving model (epoch = 2428, loss = 1.0628)\n",
      "Saving model (epoch = 2431, loss = 1.0512)\n",
      "Saving model (epoch = 2474, loss = 1.0467)\n",
      "Saving model (epoch = 2475, loss = 1.0463)\n",
      "Saving model (epoch = 2519, loss = 1.0446)\n",
      "Saving model (epoch = 2521, loss = 1.0388)\n",
      "Saving model (epoch = 2523, loss = 1.0387)\n",
      "Saving model (epoch = 2524, loss = 1.0186)\n",
      "Saving model (epoch = 2538, loss = 1.0184)\n",
      "Saving model (epoch = 2545, loss = 1.0130)\n",
      "Saving model (epoch = 2555, loss = 1.0098)\n",
      "Saving model (epoch = 2558, loss = 1.0090)\n",
      "Saving model (epoch = 2563, loss = 1.0062)\n",
      "Saving model (epoch = 2568, loss = 1.0036)\n",
      "Saving model (epoch = 2575, loss = 0.9952)\n",
      "Saving model (epoch = 2577, loss = 0.9943)\n",
      "Saving model (epoch = 2579, loss = 0.9924)\n",
      "Saving model (epoch = 2595, loss = 0.9916)\n",
      "Saving model (epoch = 2603, loss = 0.9907)\n",
      "Saving model (epoch = 2608, loss = 0.9901)\n",
      "Saving model (epoch = 2610, loss = 0.9891)\n",
      "Saving model (epoch = 2621, loss = 0.9838)\n",
      "Saving model (epoch = 2622, loss = 0.9836)\n",
      "Saving model (epoch = 2628, loss = 0.9776)\n",
      "Saving model (epoch = 2652, loss = 0.9691)\n",
      "Saving model (epoch = 2661, loss = 0.9645)\n",
      "Saving model (epoch = 2662, loss = 0.9645)\n",
      "Saving model (epoch = 2671, loss = 0.9625)\n",
      "Saving model (epoch = 2674, loss = 0.9618)\n",
      "Saving model (epoch = 2704, loss = 0.9575)\n",
      "Saving model (epoch = 2715, loss = 0.9552)\n",
      "Saving model (epoch = 2717, loss = 0.9538)\n",
      "Saving model (epoch = 2744, loss = 0.9498)\n",
      "Saving model (epoch = 2750, loss = 0.9467)\n",
      "Saving model (epoch = 2752, loss = 0.9457)\n",
      "Saving model (epoch = 2775, loss = 0.9440)\n",
      "Saving model (epoch = 2776, loss = 0.9416)\n",
      "Saving model (epoch = 2786, loss = 0.9366)\n",
      "Saving model (epoch = 2788, loss = 0.9337)\n",
      "Saving model (epoch = 2799, loss = 0.9251)\n",
      "Saving model (epoch = 2819, loss = 0.9228)\n",
      "Saving model (epoch = 2868, loss = 0.9142)\n",
      "Saving model (epoch = 2874, loss = 0.9110)\n",
      "Saving model (epoch = 2949, loss = 0.9069)\n",
      "Saving model (epoch = 3083, loss = 0.9041)\n",
      "Saving model (epoch = 3154, loss = 0.9012)\n",
      "Saving model (epoch = 3206, loss = 0.8954)\n",
      "Saving model (epoch = 3255, loss = 0.8912)\n",
      "Saving model (epoch = 3429, loss = 0.8892)\n",
      "Saving model (epoch = 3459, loss = 0.8891)\n",
      "Saving model (epoch = 3461, loss = 0.8860)\n",
      "Saving model (epoch = 3463, loss = 0.8855)\n",
      "Saving model (epoch = 3464, loss = 0.8854)\n",
      "Saving model (epoch = 3470, loss = 0.8798)\n",
      "Saving model (epoch = 3500, loss = 0.8793)\n",
      "Finished training after 3701 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2881054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(model_loss_record, title='deep model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1bee712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "del model\n",
    "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
    "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "model.load_state_dict(ckpt)\n",
    "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6acc3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to pred_advanced.csv\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
    "save_pred(preds, 'pred_advanced.csv')         # save prediction file to pred.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "dec76cbff7fd00a9f0e0ca5e0160884888f12244eabd59eecc9f974d0f3fdba0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
